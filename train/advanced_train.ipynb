{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoiJY38YZ0dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "f721ed53-c0f1-4de9-9d3a-f82055097072"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug  6 14:04:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    49W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DssQ2JMqbZiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a1f0d68-1276-43f7-e453-75113fa9c3e2"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpK6eu1ZL35y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "ed1fc463-3d95-4518-db36-8a9ad869a8c1"
      },
      "source": [
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n",
            "Requirement already up-to-date: torch==1.5 in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already up-to-date: torchvision==0.6 in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6) (7.2.0)\n",
            "1.5.0+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG2lDLZra2Wq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "outputId": "78e26e6f-9ad9-414c-9d1d-6a1646ed36b5"
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.2.1+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.0.2)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.2.0)\n",
            "Requirement already satisfied: fvcore>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.1.post20200716)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.7)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.30.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.18.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (49.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2) (2.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.1->detectron2) (5.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->detectron2) (0.29.21)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.6.20)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOyMPBJrsqwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5rTgBClrnje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "import os\n",
        "os.environ['WANDB_API_KEY'] = '2000a87a07a37c799c731975686e15079a8c188d'\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jam49slAcq-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "072ca4c5-f4b8-48fd-aec9-4f75c842812c"
      },
      "source": [
        "%cd /usr/local/lib/python3.6/dist-packages/detectron2/evaluation/\n",
        "%rm coco_evaluation.py\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/harryfb/quick_stock-taking_api/master/coco_evaluation.py'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/detectron2/evaluation\n",
            "--2020-08-06 14:04:51--  https://raw.githubusercontent.com/harryfb/quick_stock-taking_api/master/coco_evaluation.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21235 (21K) [text/plain]\n",
            "Saving to: ‘coco_evaluation.py’\n",
            "\n",
            "coco_evaluation.py  100%[===================>]  20.74K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2020-08-06 14:04:51 (2.58 MB/s) - ‘coco_evaluation.py’ saved [21235/21235]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02yNu2Fahkto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abe4455c-05f7-4d0e-ec4b-c196b4594cec"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Project/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyQvhnIa7Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import detectron2\n",
        "\n",
        "# Import common libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Import detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer  # Look into moving to a custom training loop to add weights & biases\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.config import get_cfg"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOVifnng2-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TOGGLE PROGRAM FUNCTIONALITY\n",
        "TEST_INPUT = False  # Toggles image read test\n",
        "TRAINING_CURVES = False  # Toggles Tensorboard training curves\n",
        "\n",
        "\n",
        "# PROGRAM CONSTANTS\n",
        "ROOT_DIR = \"10_class\"\n",
        "WANDB_PROJ = 'multi-class'\n",
        "model_name = \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
        "\n",
        "# TRAINING PARAMETERS\n",
        "num_classes = 10\n",
        "workers = 2\n",
        "ims_per_batch = 4\n",
        "seed = 27\n",
        "\n",
        "lr = 0.0025\n",
        "\n",
        "warmup_iters = 1000\n",
        "max_iter = 1500\n",
        "step_low = 1000\n",
        "step_high = 1500\n",
        "gamma = 0.2\n",
        "momentum = 0.99\n",
        "\n",
        "eval_period = 250\n",
        "\n",
        "# FILE PATHS\n",
        "TRAIN_DATASET_NAME = ROOT_DIR + \"_train\"\n",
        "TRAIN_ANNOTATIONS = ROOT_DIR + \"/train/annotations.json\"\n",
        "TRAIN_DIR = ROOT_DIR + \"/train\"\n",
        "\n",
        "TEST_DATASET_NAME = ROOT_DIR + \"_val\"\n",
        "TEST_ANNOTATIONS = ROOT_DIR + \"/val/annotations.json\"\n",
        "TEST_DIR = ROOT_DIR + \"/val\"\n",
        "\n",
        "output = ROOT_DIR + '/output'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrmeoAawbTbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c72ad5db-aac7-4cf4-b8b3-79487c40f709"
      },
      "source": [
        "try:\n",
        "  register_coco_instances(TRAIN_DATASET_NAME, {}, TRAIN_ANNOTATIONS, TRAIN_DIR)\n",
        "  register_coco_instances(TEST_DATASET_NAME, {}, TEST_ANNOTATIONS, TEST_DIR)\n",
        "except (AssertionError):\n",
        "  print('Dataset has aready been registered!')\n",
        "\n",
        "train_metadata = MetadataCatalog.get(TRAIN_DATASET_NAME)\n",
        "dataset_dicts = DatasetCatalog.get(TRAIN_DATASET_NAME)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "Filtered out 2 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPnSviwODxru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_bins = np.arange(num_classes + 1)\n",
        "histogram = np.zeros((num_classes,), dtype=np.int)\n",
        "for entry in dataset_dicts:\n",
        "  annos = entry[\"annotations\"]\n",
        "  classes = [x[\"category_id\"] for x in annos if not x.get(\"iscrowd\", 0)]\n",
        "  histogram += np.histogram(classes, bins=hist_bins)[0]\n",
        "\n",
        "class_instances = {('class_instances.' + train_metadata.thing_classes[i]): int(count) for i, count in enumerate(histogram)}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26pSZM1Af1EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if TEST_INPUT:\n",
        "  for d in random.sample(dataset_dicts, 3):\n",
        "      img = cv2.imread(d[\"file_name\"])\n",
        "      visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "      out = visualizer.draw_dataset_dict(d)\n",
        "      cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABvMGt82q_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from shutil import copyfile\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "from detectron2.engine import default_argument_parser, default_setup, launch\n",
        "from detectron2.evaluation import (\n",
        "    COCOEvaluator,\n",
        "    COCOPanopticEvaluator,\n",
        "    DatasetEvaluators,\n",
        "    SemSegEvaluator,\n",
        "    inference_on_dataset,\n",
        "    print_csv_format,\n",
        ")\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
        "from detectron2.utils.events import (\n",
        "    CommonMetricPrinter,\n",
        "    EventStorage,\n",
        "    JSONWriter,\n",
        "    TensorboardXWriter,\n",
        ")\n",
        "\n",
        "# Setup logger\n",
        "logger = logging.getLogger(\"detectron2\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cBPAMR25GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_evaluator(cfg, dataset_name, output_folder=None):\n",
        "    \"\"\"\n",
        "    Create evaluator(s) for a given dataset.\n",
        "    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
        "    For your own dataset, you can simply create an evaluator manually in your\n",
        "    script and do not have to worry about the hacky if-else logic here.\n",
        "\n",
        "    # TODO: Edit docstring\n",
        "\n",
        "    \"\"\"\n",
        "    if output_folder is None:\n",
        "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "    evaluator_list = []\n",
        "\n",
        "    evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
        "    if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(\n",
        "            SemSegEvaluator(\n",
        "                dataset_name,\n",
        "                distributed=True,\n",
        "                num_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES,\n",
        "                ignore_label=cfg.MODEL.SEM_SEG_HEAD.IGNORE_VALUE,\n",
        "                output_dir=output_folder,\n",
        "            )\n",
        "        )\n",
        "    if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(COCOEvaluator(dataset_name, cfg, True, output_folder))\n",
        "    if evaluator_type == \"coco_panoptic_seg\":\n",
        "        evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n",
        "\n",
        "    if len(evaluator_list) == 0:\n",
        "        raise NotImplementedError(\n",
        "            \"no Evaluator for the dataset {} with the type {}\".format(dataset_name, evaluator_type)\n",
        "        )\n",
        "    if len(evaluator_list) == 1:\n",
        "        return evaluator_list[0]\n",
        "    return DatasetEvaluators(evaluator_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj74pNfF26zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_test(cfg, model):\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Write docstring\n",
        "    \"\"\"\n",
        "    # Initialise results dictionary\n",
        "    results = OrderedDict()\n",
        "\n",
        "    # Loop through the datasets in the config file\n",
        "    for dataset_name in cfg.DATASETS.TEST:\n",
        "        data_loader = build_detection_test_loader(cfg, dataset_name)\n",
        "\n",
        "        # Generate the evaluator\n",
        "        evaluator = get_evaluator(\n",
        "            cfg,\n",
        "            dataset_name,\n",
        "            os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
        "        )\n",
        "\n",
        "        # Run inference and add to results dictionary\n",
        "        results_i = inference_on_dataset(model, data_loader, evaluator)\n",
        "        results[dataset_name] = results_i\n",
        "\n",
        "        result_log = {}\n",
        "        result_dict = results_i\n",
        "        for iou_type in result_dict:\n",
        "          for metric, result in result_dict[iou_type].items():\n",
        "            metric_log = f\"{iou_type}_{metric}\"\n",
        "            result_log[metric_log] = result\n",
        "\n",
        "        logger.debug('Log the eval results on Weights & Biases')\n",
        "        wandb.log(result_log)\n",
        "\n",
        "        if comm.is_main_process():\n",
        "            logger.info(\"Evaluation results for {} in csv format:\".format(dataset_name))\n",
        "            print_csv_format(results_i)\n",
        "    if len(results) == 1:\n",
        "        results = list(results.values())[0]\n",
        "\n",
        "    return results"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzsH_C5D2-Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_train(cfg, model, resume=False):\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Write docstring\n",
        "    \"\"\"\n",
        "    # Set the model to train\n",
        "    model.train()\n",
        "\n",
        "    # Create torch optimiser & schedulars\n",
        "    optimizer = build_optimizer(cfg, model)\n",
        "    scheduler = build_lr_scheduler(cfg, optimizer)\n",
        "\n",
        "    # Create a torch checkpointer\n",
        "    checkpointer = DetectionCheckpointer(\n",
        "        model, cfg.OUTPUT_DIR, optimizer=optimizer, scheduler=scheduler\n",
        "    )\n",
        "\n",
        "    # Create starting checkpoint i.e. pre-trained model using weights from config\n",
        "    start_iter = (\n",
        "        checkpointer.resume_or_load(cfg.MODEL.WEIGHTS, resume=resume).get(\"iteration\", -1) + 1\n",
        "    )\n",
        "\n",
        "    # Define the number of iterations\n",
        "    max_iter = cfg.SOLVER.MAX_ITER\n",
        "\n",
        "    # Create a periodic checkpointer at the configured period\n",
        "    periodic_checkpointer = PeriodicCheckpointer(\n",
        "        checkpointer, cfg.SOLVER.CHECKPOINT_PERIOD, max_iter=max_iter\n",
        "    )\n",
        "\n",
        "    # Export checkpoint data to terminal, JSON & tensorboard files\n",
        "    writers = (\n",
        "        [\n",
        "            CommonMetricPrinter(max_iter),\n",
        "            JSONWriter(os.path.join(cfg.OUTPUT_DIR, \"metrics.json\")),\n",
        "            TensorboardXWriter(cfg.OUTPUT_DIR),\n",
        "        ]\n",
        "        if comm.is_main_process()\n",
        "        else []\n",
        "    )\n",
        "\n",
        "    # Create a data loader to supply the model with training data\n",
        "    data_loader = build_detection_train_loader(cfg)\n",
        "\n",
        "    logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
        "    with EventStorage(start_iter) as storage:\n",
        "        for data, iteration in zip(data_loader, range(start_iter, max_iter)):\n",
        "            iteration = iteration + 1\n",
        "            storage.step()\n",
        "\n",
        "            loss_dict = model(data)\n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                storage.put_scalars(total_loss=losses_reduced, **loss_dict_reduced)\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            storage.put_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], smoothing_hint=False)\n",
        "            scheduler.step()\n",
        "\n",
        "            # If eval period has been set, run test at defined interval\n",
        "            if (\n",
        "                cfg.TEST.EVAL_PERIOD > 0\n",
        "                and iteration % cfg.TEST.EVAL_PERIOD == 0\n",
        "                and iteration != max_iter\n",
        "            ):\n",
        "                do_test(cfg, model)\n",
        "                comm.synchronize()\n",
        "\n",
        "            if iteration - start_iter > 5 and (iteration % 20 == 0 or iteration == max_iter):\n",
        "                logger.debug('Logging iteration and loss to Weights & Biases')\n",
        "                wandb.log({\"iteration\": iteration})\n",
        "                wandb.log({\"total_loss\": losses_reduced})\n",
        "                wandb.log(loss_dict_reduced)\n",
        "\n",
        "                for writer in writers:\n",
        "                    writer.write()\n",
        "            periodic_checkpointer.step(iteration)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTnsfBqp3Ckj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup(args, model_name):\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(args.config_file)\n",
        "    cfg.merge_from_list(args.opts)\n",
        "\n",
        "    cfg.freeze()\n",
        "\n",
        "    # Log the configuration file to OUTPUT_DIR\n",
        "    default_setup(\n",
        "        cfg, args\n",
        "    )\n",
        "\n",
        "    # Set up the weights and biases project\n",
        "    logger.debug('Initialising Weights & Biases project')\n",
        "    wandb.init(project=WANDB_PROJ, sync_tensorboard=False)\n",
        "\n",
        "    # Load the yaml file and export it to wandb\n",
        "    cfg_export = cfg.load_yaml_with_base(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"))\n",
        "    logger.debug(\"Saving cfg file to Weights & Biases\")\n",
        "    wandb.config.update(cfg_export)\n",
        "\n",
        "    # Log train and val set sizes\n",
        "    wandb.config.update({\"CONFIG_FILE\": model_name})\n",
        "    wandb.config.update({\"train_imgs\": len(dataset_dicts)})\n",
        "    wandb.config.update({\"test_imgs\": len(DatasetCatalog.get(TEST_DATASET_NAME))})\n",
        "    wandb.config.update(class_instances)\n",
        "\n",
        "    return cfg"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK8qyY0Z3Vws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(args, model_name):\n",
        "    # Initialise the configuration datastructure\n",
        "    cfg = setup(args, model_name)\n",
        "\n",
        "    # Build a model from the configuration file\n",
        "    model = build_model(cfg)\n",
        "\n",
        "    logger.info(\"Model:\\n{}\".format(model))\n",
        "\n",
        "    # If the 'eval_only' argument is present, load the last checkpoint\n",
        "    # and return the results of the test function\n",
        "    if args.eval_only:\n",
        "        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
        "            cfg.MODEL.WEIGHTS, resume=args.resume\n",
        "        )\n",
        "        return do_test(cfg, model)\n",
        "\n",
        "    # Run the training loop\n",
        "    do_train(cfg, model, resume=args.resume)\n",
        "\n",
        "\n",
        "    logger.debug('Saving model to Weights & Biases')\n",
        "    copyfile(ROOT_DIR + '/output/model_final.pth', wandb.run.dir + '/model_final.pth')\n",
        "\n",
        "    # Return the results of the model test function\n",
        "    return do_test(cfg, model)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFXyrw-FiZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "574a5b17-f80b-4a4d-cbfb-89720c90ae65"
      },
      "source": [
        "# Set up an argument string to pass into the main function\n",
        "\n",
        "config = model_zoo.get_config_file(model_name)\n",
        "weights = model_zoo.get_checkpoint_url(model_name)\n",
        "\n",
        "arg_string = f\"--config-file {config} \\\n",
        "              MODEL.WEIGHTS {weights} \\\n",
        "              OUTPUT_DIR {output} \\\n",
        "              DATASETS.TRAIN ('{TRAIN_DATASET_NAME}',) \\\n",
        "              DATASETS.TEST ('{TEST_DATASET_NAME}',) \\\n",
        "              DATALOADER.NUM_WORKERS {workers} \\\n",
        "              SOLVER.IMS_PER_BATCH {ims_per_batch} \\\n",
        "              SOLVER.BASE_LR {lr} \\\n",
        "              SOLVER.WARMUP_ITERS {warmup_iters} \\\n",
        "              SOLVER.MAX_ITER {max_iter} \\\n",
        "              SOLVER.STEPS ({step_low},{step_high}) \\\n",
        "              SOLVER.GAMMA {gamma} \\\n",
        "              SOLVER.MOMENTUM {momentum} \\\n",
        "              SEED {seed} \\\n",
        "              MODEL.ROI_HEADS.NUM_CLASSES {num_classes} \\\n",
        "              MODEL.RETINANET.NUM_CLASSES {num_classes} \\\n",
        "              TEST.EVAL_PERIOD {eval_period}\".split()\n",
        "\n",
        "parser = default_argument_parser()\n",
        "args = parser.parse_args(arg_string)\n",
        "\n",
        "main(args, model_name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
            "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ---------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.6.9 (default, Jul 17 2020, 12:50:27) [GCC 8.4.0]\n",
            "numpy                   1.18.5\n",
            "detectron2              0.2.1 @/usr/local/lib/python3.6/dist-packages/detectron2\n",
            "Compiler                GCC 7.3\n",
            "CUDA compiler           CUDA 10.1\n",
            "detectron2 arch flags   sm_35, sm_37, sm_50, sm_52, sm_60, sm_61, sm_70, sm_75\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.5.0+cu101 @/usr/local/lib/python3.6/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           True\n",
            "GPU 0                   Tesla P100-PCIE-16GB\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.2.0\n",
            "torchvision             0.6.0+cu101 @/usr/local/lib/python3.6/dist-packages/torchvision\n",
            "torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75\n",
            "fvcore                  0.1.1.post20200716\n",
            "cv2                     4.1.2\n",
            "----------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
            "\n",
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/usr/local/lib/python3.6/dist-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl', 'OUTPUT_DIR', '10_class/output', 'DATASETS.TRAIN', \"('10_class_train',)\", 'DATASETS.TEST', \"('10_class_val',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.WARMUP_ITERS', '1000', 'SOLVER.MAX_ITER', '1500', 'SOLVER.STEPS', '(1000,1500)', 'SOLVER.GAMMA', '0.2', 'SOLVER.MOMENTUM', '0.99', 'SEED', '27', 'MODEL.ROI_HEADS.NUM_CLASSES', '10', 'MODEL.RETINANET.NUM_CLASSES', '10', 'TEST.EVAL_PERIOD', '250'], resume=False)\n",
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mContents of args.config_file=/usr/local/lib/python3.6/dist-packages/detectron2/model_zoo/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml:\n",
            "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
            "MODEL:\n",
            "  MASK_ON: True\n",
            "  WEIGHTS: \"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\"\n",
            "  PIXEL_STD: [57.375, 57.120, 58.395]\n",
            "  RESNETS:\n",
            "    STRIDE_IN_1X1: False  # this is a C2 model\n",
            "    NUM_GROUPS: 32\n",
            "    WIDTH_PER_GROUP: 8\n",
            "    DEPTH: 101\n",
            "SOLVER:\n",
            "  STEPS: (210000, 250000)\n",
            "  MAX_ITER: 270000\n",
            "\n",
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mRunning with full config:\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 2\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('10_class_val',)\n",
            "  TRAIN: ('10_class_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [57.375, 57.12, 58.395]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 32\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: False\n",
            "    WIDTH_PER_GROUP: 8\n",
            "  RETINANET:\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 10\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 10\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n",
            "OUTPUT_DIR: 10_class/output\n",
            "SEED: 27\n",
            "SOLVER:\n",
            "  BASE_LR: 0.0025\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.2\n",
            "  IMS_PER_BATCH: 4\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 1500\n",
            "  MOMENTUM: 0.99\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (1000, 1500)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0.0001\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 250\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n",
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mFull config saved to 10_class/output/config.yaml\n",
            "\u001b[32m[08/06 14:04:53 detectron2]: \u001b[0mInitialising Weights & Biases project\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/harryfb/multi-class\" target=\"_blank\">https://app.wandb.ai/harryfb/multi-class</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/harryfb/multi-class/runs/3eyd8mq1\" target=\"_blank\">https://app.wandb.ai/harryfb/multi-class/runs/3eyd8mq1</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[08/06 14:04:54 detectron2]: \u001b[0mSaving cfg file to Weights & Biases\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:54 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:04:54 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 14:04:58 detectron2]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (6): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (7): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (8): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (9): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (10): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (11): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (12): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (13): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (14): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (15): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (16): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (17): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (18): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (19): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (20): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (21): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (22): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[08/06 14:04:58 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n",
            "\u001b[32m[08/06 14:04:58 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl cached in /root/.torch/fvcore_cache/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n",
            "\u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (10, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
            "\u001b[32m[08/06 14:04:59 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
            "  \u001b[34mroi_heads.mask_head.predictor.{weight, bias}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:05:00 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:05:00 d2.data.datasets.coco]: \u001b[0mLoaded 1200 images in COCO format from 10_class/train/annotations.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:05:00 d2.data.datasets.coco]: \u001b[0mFiltered out 2 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n",
            "\u001b[32m[08/06 14:05:00 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1200 images left.\n",
            "\u001b[32m[08/06 14:05:00 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |  category   | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|:-----------:|:-------------|\n",
            "|    cereal     | 428          | condiment  | 739          |    Bread    | 702          |\n",
            "|     pasta     | 284          |    milk    | 694          |     egg     | 757          |\n",
            "| tinned toma.. | 248          |   butter   | 722          | baked beans | 412          |\n",
            "|     soup      | 453          |            |              |             |              |\n",
            "|     total     | 5439         |            |              |             |              |\u001b[0m\n",
            "\u001b[32m[08/06 14:05:00 d2.data.common]: \u001b[0mSerializing 1200 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 14:05:00 d2.data.common]: \u001b[0mSerialized dataset takes 2.48 MiB\n",
            "\u001b[32m[08/06 14:05:00 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[08/06 14:05:00 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[08/06 14:05:00 detectron2]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[08/06 14:05:38 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:05:38 d2.utils.events]: \u001b[0m iter: 20  total_loss: 3.372  loss_cls: 2.425  loss_box_reg: 0.238  loss_mask: 0.685  loss_rpn_cls: 0.009  loss_rpn_loc: 0.013  lr: 0.000050  max_mem: 11289M\n",
            "\u001b[32m[08/06 14:06:14 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:06:14 d2.utils.events]: \u001b[0m eta: 0:44:02  iter: 40  total_loss: 1.510  loss_cls: 0.574  loss_box_reg: 0.243  loss_mask: 0.628  loss_rpn_cls: 0.015  loss_rpn_loc: 0.015  lr: 0.000100  max_mem: 11420M\n",
            "\u001b[32m[08/06 14:06:52 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:06:52 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 60  total_loss: 1.622  loss_cls: 0.757  loss_box_reg: 0.294  loss_mask: 0.482  loss_rpn_cls: 0.020  loss_rpn_loc: 0.033  lr: 0.000150  max_mem: 11615M\n",
            "\u001b[32m[08/06 14:07:28 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:07:28 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 80  total_loss: 1.118  loss_cls: 0.371  loss_box_reg: 0.289  loss_mask: 0.380  loss_rpn_cls: 0.035  loss_rpn_loc: 0.034  lr: 0.000200  max_mem: 11615M\n",
            "\u001b[32m[08/06 14:08:04 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:08:04 d2.utils.events]: \u001b[0m eta: 0:42:44  iter: 100  total_loss: 1.177  loss_cls: 0.401  loss_box_reg: 0.365  loss_mask: 0.355  loss_rpn_cls: 0.032  loss_rpn_loc: 0.031  lr: 0.000250  max_mem: 11615M\n",
            "\u001b[32m[08/06 14:08:42 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:08:42 d2.utils.events]: \u001b[0m eta: 0:43:00  iter: 120  total_loss: 0.929  loss_cls: 0.317  loss_box_reg: 0.319  loss_mask: 0.234  loss_rpn_cls: 0.015  loss_rpn_loc: 0.027  lr: 0.000300  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:09:20 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:09:20 d2.utils.events]: \u001b[0m eta: 0:43:19  iter: 140  total_loss: 0.980  loss_cls: 0.349  loss_box_reg: 0.361  loss_mask: 0.262  loss_rpn_cls: 0.015  loss_rpn_loc: 0.034  lr: 0.000350  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:09:57 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:09:57 d2.utils.events]: \u001b[0m eta: 0:42:04  iter: 160  total_loss: 0.823  loss_cls: 0.301  loss_box_reg: 0.294  loss_mask: 0.176  loss_rpn_cls: 0.032  loss_rpn_loc: 0.020  lr: 0.000400  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:10:35 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:10:35 d2.utils.events]: \u001b[0m eta: 0:41:21  iter: 180  total_loss: 0.908  loss_cls: 0.311  loss_box_reg: 0.299  loss_mask: 0.164  loss_rpn_cls: 0.022  loss_rpn_loc: 0.039  lr: 0.000450  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:11:12 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:11:12 d2.utils.events]: \u001b[0m eta: 0:39:29  iter: 200  total_loss: 0.934  loss_cls: 0.340  loss_box_reg: 0.343  loss_mask: 0.184  loss_rpn_cls: 0.022  loss_rpn_loc: 0.035  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:11:50 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:11:50 d2.utils.events]: \u001b[0m eta: 0:40:53  iter: 220  total_loss: 0.844  loss_cls: 0.333  loss_box_reg: 0.362  loss_mask: 0.144  loss_rpn_cls: 0.013  loss_rpn_loc: 0.025  lr: 0.000549  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:12:28 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:12:28 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 240  total_loss: 0.803  loss_cls: 0.298  loss_box_reg: 0.310  loss_mask: 0.154  loss_rpn_cls: 0.017  loss_rpn_loc: 0.027  lr: 0.000599  max_mem: 11817M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:12:46 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:12:46 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 14:12:46 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
            "\u001b[36m|   category    | #instances   |  category  | #instances   |  category   | #instances   |\n",
            "|:-------------:|:-------------|:----------:|:-------------|:-----------:|:-------------|\n",
            "|    cereal     | 40           | condiment  | 40           |    bread    | 40           |\n",
            "|     pasta     | 40           |    milk    | 40           |     egg     | 40           |\n",
            "| tinned toma.. | 40           |   butter   | 40           | baked beans | 40           |\n",
            "|     soup      | 40           |            |              |             |              |\n",
            "|     total     | 400          |            |              |             |              |\u001b[0m\n",
            "\u001b[32m[08/06 14:12:46 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 14:12:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[08/06 14:12:46 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/06 14:12:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 400 images\n",
            "\u001b[32m[08/06 14:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/400. 0.1924 s / img. ETA=0:02:19\n",
            "\u001b[32m[08/06 14:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 24/400. 0.1937 s / img. ETA=0:02:21\n",
            "\u001b[32m[08/06 14:13:07 d2.evaluation.evaluator]: \u001b[0mInference done 25/400. 0.1991 s / img. ETA=0:03:59\n",
            "\u001b[32m[08/06 14:13:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/400. 0.1963 s / img. ETA=0:03:04\n",
            "\u001b[32m[08/06 14:13:17 d2.evaluation.evaluator]: \u001b[0mInference done 46/400. 0.1982 s / img. ETA=0:03:18\n",
            "\u001b[32m[08/06 14:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 61/400. 0.1944 s / img. ETA=0:02:53\n",
            "\u001b[32m[08/06 14:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 69/400. 0.1947 s / img. ETA=0:03:06\n",
            "\u001b[32m[08/06 14:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 72/400. 0.1959 s / img. ETA=0:03:24\n",
            "\u001b[32m[08/06 14:13:42 d2.evaluation.evaluator]: \u001b[0mInference done 75/400. 0.1970 s / img. ETA=0:03:40\n",
            "\u001b[32m[08/06 14:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 81/400. 0.1987 s / img. ETA=0:03:47\n",
            "\u001b[32m[08/06 14:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 83/400. 0.1995 s / img. ETA=0:04:02\n",
            "\u001b[32m[08/06 14:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 94/400. 0.2010 s / img. ETA=0:03:58\n",
            "\u001b[32m[08/06 14:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 103/400. 0.2025 s / img. ETA=0:03:50\n",
            "\u001b[32m[08/06 14:14:17 d2.evaluation.evaluator]: \u001b[0mInference done 116/400. 0.2020 s / img. ETA=0:03:31\n",
            "\u001b[32m[08/06 14:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 135/400. 0.1992 s / img. ETA=0:03:06\n",
            "\u001b[32m[08/06 14:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 141/400. 0.1993 s / img. ETA=0:03:05\n",
            "\u001b[32m[08/06 14:14:38 d2.evaluation.evaluator]: \u001b[0mInference done 148/400. 0.1996 s / img. ETA=0:03:02\n",
            "\u001b[32m[08/06 14:14:43 d2.evaluation.evaluator]: \u001b[0mInference done 157/400. 0.1999 s / img. ETA=0:02:53\n",
            "\u001b[32m[08/06 14:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 164/400. 0.2000 s / img. ETA=0:02:48\n",
            "\u001b[32m[08/06 14:14:53 d2.evaluation.evaluator]: \u001b[0mInference done 177/400. 0.1989 s / img. ETA=0:02:33\n",
            "\u001b[32m[08/06 14:14:58 d2.evaluation.evaluator]: \u001b[0mInference done 188/400. 0.1993 s / img. ETA=0:02:23\n",
            "\u001b[32m[08/06 14:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 198/400. 0.2002 s / img. ETA=0:02:15\n",
            "\u001b[32m[08/06 14:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 216/400. 0.1997 s / img. ETA=0:01:57\n",
            "\u001b[32m[08/06 14:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 221/400. 0.2002 s / img. ETA=0:01:56\n",
            "\u001b[32m[08/06 14:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 224/400. 0.2006 s / img. ETA=0:01:57\n",
            "\u001b[32m[08/06 14:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 235/400. 0.2005 s / img. ETA=0:01:49\n",
            "\u001b[32m[08/06 14:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 241/400. 0.2006 s / img. ETA=0:01:46\n",
            "\u001b[32m[08/06 14:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 246/400. 0.2017 s / img. ETA=0:01:43\n",
            "\u001b[32m[08/06 14:15:43 d2.evaluation.evaluator]: \u001b[0mInference done 252/400. 0.2021 s / img. ETA=0:01:41\n",
            "\u001b[32m[08/06 14:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 260/400. 0.2022 s / img. ETA=0:01:36\n",
            "\u001b[32m[08/06 14:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 266/400. 0.2022 s / img. ETA=0:01:32\n",
            "\u001b[32m[08/06 14:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 270/400. 0.2031 s / img. ETA=0:01:33\n",
            "\u001b[32m[08/06 14:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 286/400. 0.2027 s / img. ETA=0:01:20\n",
            "\u001b[32m[08/06 14:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 298/400. 0.2023 s / img. ETA=0:01:11\n",
            "\u001b[32m[08/06 14:16:25 d2.evaluation.evaluator]: \u001b[0mInference done 306/400. 0.2020 s / img. ETA=0:01:05\n",
            "\u001b[32m[08/06 14:16:30 d2.evaluation.evaluator]: \u001b[0mInference done 327/400. 0.2010 s / img. ETA=0:00:48\n",
            "\u001b[32m[08/06 14:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 341/400. 0.2007 s / img. ETA=0:00:39\n",
            "\u001b[32m[08/06 14:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 351/400. 0.2008 s / img. ETA=0:00:33\n",
            "\u001b[32m[08/06 14:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 357/400. 0.2009 s / img. ETA=0:00:29\n",
            "\u001b[32m[08/06 14:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 362/400. 0.2011 s / img. ETA=0:00:26\n",
            "\u001b[32m[08/06 14:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 369/400. 0.2009 s / img. ETA=0:00:21\n",
            "\u001b[32m[08/06 14:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 387/400. 0.2008 s / img. ETA=0:00:08\n",
            "\u001b[32m[08/06 14:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 391/400. 0.2009 s / img. ETA=0:00:06\n",
            "\u001b[32m[08/06 14:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 400/400. 0.2010 s / img. ETA=0:00:00\n",
            "\u001b[32m[08/06 14:17:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:35.444201 (0.697327 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:17:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:19 (0.200958 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:17:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/06 14:17:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 10_class/output/inference/10_class_val/coco_instances_results.json\n",
            "\u001b[32m[08/06 14:17:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.35 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.417\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511\n",
            "\u001b[32m[08/06 14:17:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:-----:|:------:|:------:|:-----:|:------:|:-----:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 5.257 | 13.288 | 2.541  |  nan  | 40.000 | 5.246 | 41.700 | 51.075 | 51.075  |  nan  | 50.000 | 51.085 |\n",
            "\u001b[32m[08/06 14:17:32 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:17:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category   | AP    | category    | AP    |\n",
            "|:----------------|:-------|:-----------|:------|:------------|:------|\n",
            "| cereal          | 5.122  | condiment  | 4.977 | bread       | 2.918 |\n",
            "| pasta           | 1.957  | milk       | 5.530 | egg         | 2.507 |\n",
            "| tinned tomatoes | 3.919  | butter     | 5.505 | baked beans | 7.286 |\n",
            "| soup            | 12.853 |            |       |             |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.64s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "COCOeval_opt.evaluate() finished in 0.49 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.05 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.725\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.598\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.709\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:-----:|:------:|:------:|:-----:|:------:|:-----:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 8.509 | 13.523 | 9.262  |  nan  | 72.500 | 8.471 | 59.825 | 70.950 | 70.950  |  nan  | 90.000 | 70.894 |\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category        | AP     | category   | AP    | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:------|:------------|:-------|\n",
            "| cereal          | 7.155  | condiment  | 7.210 | bread       | 4.508  |\n",
            "| pasta           | 2.833  | milk       | 7.487 | egg         | 3.476  |\n",
            "| tinned tomatoes | 12.467 | butter     | 9.978 | baked beans | 13.680 |\n",
            "| soup            | 16.298 |            |       |             |        |\n",
            "\u001b[32m[08/06 14:17:34 detectron2]: \u001b[0mLog the eval results on Weights & Biases\n",
            "\u001b[32m[08/06 14:17:34 detectron2]: \u001b[0mEvaluation results for 10_class_val in csv format:\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2573,13.2880,2.5410,nan,40.0000,5.2461,41.7000,51.0750,51.0750,nan,50.0000,51.0853\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:17:34 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5091,13.5234,9.2625,nan,72.5000,8.4712,59.8250,70.9500,70.9500,nan,90.0000,70.8942\n",
            "\u001b[32m[08/06 14:17:54 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:17:54 d2.utils.events]: \u001b[0m eta: 5:36:47  iter: 260  total_loss: 0.790  loss_cls: 0.278  loss_box_reg: 0.283  loss_mask: 0.160  loss_rpn_cls: 0.020  loss_rpn_loc: 0.033  lr: 0.000649  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:18:32 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:18:32 d2.utils.events]: \u001b[0m eta: 0:39:01  iter: 280  total_loss: 0.687  loss_cls: 0.262  loss_box_reg: 0.278  loss_mask: 0.120  loss_rpn_cls: 0.009  loss_rpn_loc: 0.027  lr: 0.000699  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:19:10 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:19:10 d2.utils.events]: \u001b[0m eta: 0:37:40  iter: 300  total_loss: 0.921  loss_cls: 0.330  loss_box_reg: 0.302  loss_mask: 0.177  loss_rpn_cls: 0.017  loss_rpn_loc: 0.025  lr: 0.000749  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:19:46 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:19:46 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 320  total_loss: 0.677  loss_cls: 0.231  loss_box_reg: 0.234  loss_mask: 0.149  loss_rpn_cls: 0.007  loss_rpn_loc: 0.025  lr: 0.000799  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:20:23 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:20:23 d2.utils.events]: \u001b[0m eta: 0:35:08  iter: 340  total_loss: 0.792  loss_cls: 0.310  loss_box_reg: 0.292  loss_mask: 0.142  loss_rpn_cls: 0.010  loss_rpn_loc: 0.025  lr: 0.000849  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:20:59 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:20:59 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 360  total_loss: 0.696  loss_cls: 0.265  loss_box_reg: 0.239  loss_mask: 0.145  loss_rpn_cls: 0.007  loss_rpn_loc: 0.028  lr: 0.000899  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:21:35 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:21:35 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 380  total_loss: 0.790  loss_cls: 0.340  loss_box_reg: 0.280  loss_mask: 0.141  loss_rpn_cls: 0.008  loss_rpn_loc: 0.028  lr: 0.000949  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:22:10 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:22:10 d2.utils.events]: \u001b[0m eta: 0:32:31  iter: 400  total_loss: 0.830  loss_cls: 0.351  loss_box_reg: 0.245  loss_mask: 0.154  loss_rpn_cls: 0.016  loss_rpn_loc: 0.035  lr: 0.000999  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:22:47 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:22:47 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 420  total_loss: 0.537  loss_cls: 0.232  loss_box_reg: 0.145  loss_mask: 0.106  loss_rpn_cls: 0.007  loss_rpn_loc: 0.025  lr: 0.001049  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:23:24 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:23:24 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 440  total_loss: 0.711  loss_cls: 0.300  loss_box_reg: 0.179  loss_mask: 0.123  loss_rpn_cls: 0.010  loss_rpn_loc: 0.023  lr: 0.001099  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:24:02 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:24:02 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 460  total_loss: 0.564  loss_cls: 0.218  loss_box_reg: 0.157  loss_mask: 0.162  loss_rpn_cls: 0.013  loss_rpn_loc: 0.044  lr: 0.001149  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:24:40 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:24:40 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 480  total_loss: 0.563  loss_cls: 0.230  loss_box_reg: 0.140  loss_mask: 0.155  loss_rpn_cls: 0.013  loss_rpn_loc: 0.023  lr: 0.001199  max_mem: 11817M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:25:17 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:25:17 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 14:25:17 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 14:25:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[08/06 14:25:17 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/06 14:25:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 400 images\n",
            "\u001b[32m[08/06 14:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/400. 0.1889 s / img. ETA=0:02:00\n",
            "\u001b[32m[08/06 14:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 25/400. 0.1885 s / img. ETA=0:02:50\n",
            "\u001b[32m[08/06 14:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 42/400. 0.1883 s / img. ETA=0:02:25\n",
            "\u001b[32m[08/06 14:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 62/400. 0.1853 s / img. ETA=0:02:00\n",
            "\u001b[32m[08/06 14:25:56 d2.evaluation.evaluator]: \u001b[0mInference done 75/400. 0.1878 s / img. ETA=0:02:47\n",
            "\u001b[32m[08/06 14:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 87/400. 0.1888 s / img. ETA=0:02:36\n",
            "\u001b[32m[08/06 14:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 94/400. 0.1895 s / img. ETA=0:02:44\n",
            "\u001b[32m[08/06 14:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 103/400. 0.1898 s / img. ETA=0:02:50\n",
            "\u001b[32m[08/06 14:26:21 d2.evaluation.evaluator]: \u001b[0mInference done 116/400. 0.1896 s / img. ETA=0:02:37\n",
            "\u001b[32m[08/06 14:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 135/400. 0.1879 s / img. ETA=0:02:22\n",
            "\u001b[32m[08/06 14:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 148/400. 0.1882 s / img. ETA=0:02:22\n",
            "\u001b[32m[08/06 14:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 160/400. 0.1893 s / img. ETA=0:02:19\n",
            "\u001b[32m[08/06 14:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 176/400. 0.1884 s / img. ETA=0:02:04\n",
            "\u001b[32m[08/06 14:27:02 d2.evaluation.evaluator]: \u001b[0mInference done 187/400. 0.1887 s / img. ETA=0:01:59\n",
            "\u001b[32m[08/06 14:27:07 d2.evaluation.evaluator]: \u001b[0mInference done 198/400. 0.1893 s / img. ETA=0:01:52\n",
            "\u001b[32m[08/06 14:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 219/400. 0.1893 s / img. ETA=0:01:36\n",
            "\u001b[32m[08/06 14:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 224/400. 0.1898 s / img. ETA=0:01:36\n",
            "\u001b[32m[08/06 14:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 236/400. 0.1899 s / img. ETA=0:01:29\n",
            "\u001b[32m[08/06 14:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 244/400. 0.1902 s / img. ETA=0:01:25\n",
            "\u001b[32m[08/06 14:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 254/400. 0.1907 s / img. ETA=0:01:21\n",
            "\u001b[32m[08/06 14:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 264/400. 0.1907 s / img. ETA=0:01:15\n",
            "\u001b[32m[08/06 14:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 270/400. 0.1916 s / img. ETA=0:01:15\n",
            "\u001b[32m[08/06 14:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 287/400. 0.1915 s / img. ETA=0:01:03\n",
            "\u001b[32m[08/06 14:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 304/400. 0.1910 s / img. ETA=0:00:52\n",
            "\u001b[32m[08/06 14:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 328/400. 0.1902 s / img. ETA=0:00:37\n",
            "\u001b[32m[08/06 14:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 345/400. 0.1898 s / img. ETA=0:00:28\n",
            "\u001b[32m[08/06 14:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 356/400. 0.1898 s / img. ETA=0:00:23\n",
            "\u001b[32m[08/06 14:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 363/400. 0.1899 s / img. ETA=0:00:19\n",
            "\u001b[32m[08/06 14:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 377/400. 0.1895 s / img. ETA=0:00:11\n",
            "\u001b[32m[08/06 14:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 387/400. 0.1898 s / img. ETA=0:00:06\n",
            "\u001b[32m[08/06 14:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 393/400. 0.1898 s / img. ETA=0:00:03\n",
            "\u001b[32m[08/06 14:28:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:29.004602 (0.529126 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:28:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:14 (0.189788 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:28:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/06 14:28:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 10_class/output/inference/10_class_val/coco_instances_results.json\n",
            "\u001b[32m[08/06 14:28:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.19 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.606\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
            "\u001b[32m[08/06 14:28:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 16.122 | 25.941 | 18.394 |  nan  | 70.000 | 16.099 | 60.625 | 64.800 | 64.875  |  nan  | 70.000 | 64.845 |\n",
            "\u001b[32m[08/06 14:28:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:28:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 8.212  | condiment  | 18.198 | bread       | 3.587  |\n",
            "| pasta           | 22.779 | milk       | 23.841 | egg         | 24.714 |\n",
            "| tinned tomatoes | 13.468 | butter     | 21.665 | baked beans | 15.182 |\n",
            "| soup            | 9.578  |            |        |             |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.30s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "COCOeval_opt.evaluate() finished in 0.52 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.773\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.774\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 20.401 | 25.820 | 22.926 |  nan  | 90.000 | 20.441 | 72.575 | 77.275 | 77.375  |  nan  | 90.000 | 77.346 |\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 9.332  | condiment  | 22.892 | bread       | 3.901  |\n",
            "| pasta           | 26.084 | milk       | 28.636 | egg         | 32.732 |\n",
            "| tinned tomatoes | 16.547 | butter     | 31.692 | baked beans | 19.921 |\n",
            "| soup            | 12.271 |            |        |             |        |\n",
            "\u001b[32m[08/06 14:28:51 detectron2]: \u001b[0mLog the eval results on Weights & Biases\n",
            "\u001b[32m[08/06 14:28:51 detectron2]: \u001b[0mEvaluation results for 10_class_val in csv format:\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.testing]: \u001b[0mcopypaste: 16.1224,25.9413,18.3945,nan,70.0000,16.0991,60.6250,64.8000,64.8750,nan,70.0000,64.8449\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:28:51 d2.evaluation.testing]: \u001b[0mcopypaste: 20.4009,25.8196,22.9256,nan,90.0000,20.4412,72.5750,77.2750,77.3750,nan,90.0000,77.3455\n",
            "\u001b[32m[08/06 14:28:51 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:28:51 d2.utils.events]: \u001b[0m eta: 3:29:13  iter: 500  total_loss: 0.778  loss_cls: 0.315  loss_box_reg: 0.177  loss_mask: 0.170  loss_rpn_cls: 0.016  loss_rpn_loc: 0.037  lr: 0.001249  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:29:28 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:29:28 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 520  total_loss: 0.680  loss_cls: 0.282  loss_box_reg: 0.169  loss_mask: 0.143  loss_rpn_cls: 0.011  loss_rpn_loc: 0.032  lr: 0.001299  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:30:04 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:30:04 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 540  total_loss: 0.747  loss_cls: 0.297  loss_box_reg: 0.170  loss_mask: 0.199  loss_rpn_cls: 0.016  loss_rpn_loc: 0.030  lr: 0.001349  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:30:41 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:30:41 d2.utils.events]: \u001b[0m eta: 0:29:03  iter: 560  total_loss: 0.890  loss_cls: 0.386  loss_box_reg: 0.205  loss_mask: 0.161  loss_rpn_cls: 0.017  loss_rpn_loc: 0.031  lr: 0.001399  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:31:18 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:31:18 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 580  total_loss: 0.672  loss_cls: 0.318  loss_box_reg: 0.166  loss_mask: 0.154  loss_rpn_cls: 0.010  loss_rpn_loc: 0.025  lr: 0.001449  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:31:54 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:31:54 d2.utils.events]: \u001b[0m eta: 0:27:11  iter: 600  total_loss: 0.637  loss_cls: 0.248  loss_box_reg: 0.145  loss_mask: 0.203  loss_rpn_cls: 0.012  loss_rpn_loc: 0.027  lr: 0.001499  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:32:31 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:32:31 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 620  total_loss: 0.604  loss_cls: 0.289  loss_box_reg: 0.149  loss_mask: 0.138  loss_rpn_cls: 0.010  loss_rpn_loc: 0.026  lr: 0.001548  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:33:07 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:33:07 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 640  total_loss: 0.687  loss_cls: 0.311  loss_box_reg: 0.182  loss_mask: 0.184  loss_rpn_cls: 0.011  loss_rpn_loc: 0.032  lr: 0.001598  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:33:43 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:33:43 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 660  total_loss: 0.591  loss_cls: 0.259  loss_box_reg: 0.138  loss_mask: 0.143  loss_rpn_cls: 0.009  loss_rpn_loc: 0.025  lr: 0.001648  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:34:20 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:34:20 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 680  total_loss: 0.634  loss_cls: 0.260  loss_box_reg: 0.138  loss_mask: 0.132  loss_rpn_cls: 0.010  loss_rpn_loc: 0.018  lr: 0.001698  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:34:56 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:34:56 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 700  total_loss: 0.569  loss_cls: 0.230  loss_box_reg: 0.127  loss_mask: 0.126  loss_rpn_cls: 0.009  loss_rpn_loc: 0.028  lr: 0.001748  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:35:32 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:35:32 d2.utils.events]: \u001b[0m eta: 0:23:33  iter: 720  total_loss: 0.666  loss_cls: 0.287  loss_box_reg: 0.153  loss_mask: 0.141  loss_rpn_cls: 0.008  loss_rpn_loc: 0.022  lr: 0.001798  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:36:09 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:36:09 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 740  total_loss: 0.582  loss_cls: 0.263  loss_box_reg: 0.142  loss_mask: 0.164  loss_rpn_cls: 0.007  loss_rpn_loc: 0.038  lr: 0.001848  max_mem: 11817M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:36:29 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:36:29 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 14:36:29 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 14:36:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[08/06 14:36:29 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/06 14:36:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 400 images\n",
            "\u001b[32m[08/06 14:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/400. 0.1794 s / img. ETA=0:01:26\n",
            "\u001b[32m[08/06 14:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 27/400. 0.1814 s / img. ETA=0:01:47\n",
            "\u001b[32m[08/06 14:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 46/400. 0.1838 s / img. ETA=0:01:39\n",
            "\u001b[32m[08/06 14:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 68/400. 0.1810 s / img. ETA=0:01:27\n",
            "\u001b[32m[08/06 14:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 81/400. 0.1825 s / img. ETA=0:01:32\n",
            "\u001b[32m[08/06 14:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 94/400. 0.1828 s / img. ETA=0:01:36\n",
            "\u001b[32m[08/06 14:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 103/400. 0.1833 s / img. ETA=0:01:44\n",
            "\u001b[32m[08/06 14:37:11 d2.evaluation.evaluator]: \u001b[0mInference done 120/400. 0.1834 s / img. ETA=0:01:35\n",
            "\u001b[32m[08/06 14:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 141/400. 0.1819 s / img. ETA=0:01:26\n",
            "\u001b[32m[08/06 14:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 150/400. 0.1827 s / img. ETA=0:01:27\n",
            "\u001b[32m[08/06 14:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 163/400. 0.1832 s / img. ETA=0:01:24\n",
            "\u001b[32m[08/06 14:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 181/400. 0.1827 s / img. ETA=0:01:16\n",
            "\u001b[32m[08/06 14:37:38 d2.evaluation.evaluator]: \u001b[0mInference done 194/400. 0.1834 s / img. ETA=0:01:12\n",
            "\u001b[32m[08/06 14:37:43 d2.evaluation.evaluator]: \u001b[0mInference done 215/400. 0.1839 s / img. ETA=0:01:03\n",
            "\u001b[32m[08/06 14:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 224/400. 0.1843 s / img. ETA=0:01:01\n",
            "\u001b[32m[08/06 14:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 241/400. 0.1844 s / img. ETA=0:00:55\n",
            "\u001b[32m[08/06 14:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 252/400. 0.1851 s / img. ETA=0:00:52\n",
            "\u001b[32m[08/06 14:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 263/400. 0.1850 s / img. ETA=0:00:49\n",
            "\u001b[32m[08/06 14:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 274/400. 0.1855 s / img. ETA=0:00:45\n",
            "\u001b[32m[08/06 14:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 294/400. 0.1854 s / img. ETA=0:00:37\n",
            "\u001b[32m[08/06 14:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 313/400. 0.1853 s / img. ETA=0:00:30\n",
            "\u001b[32m[08/06 14:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 338/400. 0.1847 s / img. ETA=0:00:21\n",
            "\u001b[32m[08/06 14:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 353/400. 0.1845 s / img. ETA=0:00:16\n",
            "\u001b[32m[08/06 14:38:36 d2.evaluation.evaluator]: \u001b[0mInference done 366/400. 0.1845 s / img. ETA=0:00:11\n",
            "\u001b[32m[08/06 14:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 387/400. 0.1846 s / img. ETA=0:00:04\n",
            "\u001b[32m[08/06 14:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 394/400. 0.1846 s / img. ETA=0:00:02\n",
            "\u001b[32m[08/06 14:38:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:19.805201 (0.353937 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:38:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.184520 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:38:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/06 14:38:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 10_class/output/inference/10_class_val/coco_instances_results.json\n",
            "\u001b[32m[08/06 14:38:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.15 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.700\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            "\u001b[32m[08/06 14:38:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 20.564 | 30.390 | 23.814 |  nan  | 90.000 | 20.701 | 70.000 | 72.550 | 72.550  |  nan  | 90.000 | 72.478 |\n",
            "\u001b[32m[08/06 14:38:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:38:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 22.993 | condiment  | 21.545 | bread       | 6.417  |\n",
            "| pasta           | 13.821 | milk       | 25.904 | egg         | 23.317 |\n",
            "| tinned tomatoes | 18.619 | butter     | 28.839 | baked beans | 28.971 |\n",
            "| soup            | 15.211 |            |        |             |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "COCOeval_opt.evaluate() finished in 0.46 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.838\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.838\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.950\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 24.898 | 30.214 | 27.120 |  nan  | 70.000 | 25.117 | 80.800 | 83.775 | 83.775  |  nan  | 95.000 | 83.738 |\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 25.929 | condiment  | 24.280 | bread       | 7.734  |\n",
            "| pasta           | 16.419 | milk       | 30.999 | egg         | 31.816 |\n",
            "| tinned tomatoes | 24.857 | butter     | 33.484 | baked beans | 34.640 |\n",
            "| soup            | 18.826 |            |        |             |        |\n",
            "\u001b[32m[08/06 14:38:53 detectron2]: \u001b[0mLog the eval results on Weights & Biases\n",
            "\u001b[32m[08/06 14:38:53 detectron2]: \u001b[0mEvaluation results for 10_class_val in csv format:\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.testing]: \u001b[0mcopypaste: 20.5637,30.3905,23.8135,nan,90.0000,20.7009,70.0000,72.5500,72.5500,nan,90.0000,72.4776\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:38:53 d2.evaluation.testing]: \u001b[0mcopypaste: 24.8984,30.2140,27.1200,nan,70.0000,25.1172,80.8000,83.7750,83.7750,nan,95.0000,83.7385\n",
            "\u001b[32m[08/06 14:39:11 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:39:11 d2.utils.events]: \u001b[0m eta: 1:51:57  iter: 760  total_loss: 0.594  loss_cls: 0.264  loss_box_reg: 0.149  loss_mask: 0.126  loss_rpn_cls: 0.012  loss_rpn_loc: 0.031  lr: 0.001898  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:39:48 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:39:48 d2.utils.events]: \u001b[0m eta: 0:22:13  iter: 780  total_loss: 0.582  loss_cls: 0.229  loss_box_reg: 0.119  loss_mask: 0.144  loss_rpn_cls: 0.011  loss_rpn_loc: 0.025  lr: 0.001948  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:40:23 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:40:23 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 800  total_loss: 0.579  loss_cls: 0.240  loss_box_reg: 0.131  loss_mask: 0.152  loss_rpn_cls: 0.014  loss_rpn_loc: 0.028  lr: 0.001998  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:41:00 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:41:00 d2.utils.events]: \u001b[0m eta: 0:20:56  iter: 820  total_loss: 0.534  loss_cls: 0.236  loss_box_reg: 0.115  loss_mask: 0.109  loss_rpn_cls: 0.016  loss_rpn_loc: 0.028  lr: 0.002048  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:41:37 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:41:37 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 840  total_loss: 0.622  loss_cls: 0.271  loss_box_reg: 0.145  loss_mask: 0.134  loss_rpn_cls: 0.011  loss_rpn_loc: 0.029  lr: 0.002098  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:42:13 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:42:13 d2.utils.events]: \u001b[0m eta: 0:19:13  iter: 860  total_loss: 0.593  loss_cls: 0.265  loss_box_reg: 0.136  loss_mask: 0.148  loss_rpn_cls: 0.015  loss_rpn_loc: 0.029  lr: 0.002148  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:42:49 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:42:49 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 880  total_loss: 0.645  loss_cls: 0.259  loss_box_reg: 0.125  loss_mask: 0.186  loss_rpn_cls: 0.013  loss_rpn_loc: 0.030  lr: 0.002198  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:43:25 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:43:25 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 900  total_loss: 0.582  loss_cls: 0.238  loss_box_reg: 0.142  loss_mask: 0.156  loss_rpn_cls: 0.012  loss_rpn_loc: 0.028  lr: 0.002248  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:44:02 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:44:02 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 920  total_loss: 0.569  loss_cls: 0.230  loss_box_reg: 0.142  loss_mask: 0.135  loss_rpn_cls: 0.013  loss_rpn_loc: 0.028  lr: 0.002298  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:44:39 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:44:40 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 940  total_loss: 0.536  loss_cls: 0.231  loss_box_reg: 0.119  loss_mask: 0.155  loss_rpn_cls: 0.010  loss_rpn_loc: 0.033  lr: 0.002348  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:45:17 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:45:17 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 960  total_loss: 0.668  loss_cls: 0.261  loss_box_reg: 0.134  loss_mask: 0.144  loss_rpn_cls: 0.011  loss_rpn_loc: 0.038  lr: 0.002398  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:45:55 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:45:55 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 980  total_loss: 0.721  loss_cls: 0.278  loss_box_reg: 0.163  loss_mask: 0.181  loss_rpn_cls: 0.019  loss_rpn_loc: 0.048  lr: 0.002448  max_mem: 11817M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:46:31 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:46:31 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 14:46:31 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 14:46:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[08/06 14:46:31 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/06 14:46:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 400 images\n",
            "\u001b[32m[08/06 14:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/400. 0.1836 s / img. ETA=0:01:39\n",
            "\u001b[32m[08/06 14:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 28/400. 0.1831 s / img. ETA=0:01:48\n",
            "\u001b[32m[08/06 14:46:46 d2.evaluation.evaluator]: \u001b[0mInference done 49/400. 0.1834 s / img. ETA=0:01:33\n",
            "\u001b[32m[08/06 14:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 67/400. 0.1829 s / img. ETA=0:01:30\n",
            "\u001b[32m[08/06 14:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 75/400. 0.1840 s / img. ETA=0:01:46\n",
            "\u001b[32m[08/06 14:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 86/400. 0.1850 s / img. ETA=0:01:48\n",
            "\u001b[32m[08/06 14:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 97/400. 0.1855 s / img. ETA=0:01:50\n",
            "\u001b[32m[08/06 14:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 109/400. 0.1851 s / img. ETA=0:01:47\n",
            "\u001b[32m[08/06 14:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 126/400. 0.1844 s / img. ETA=0:01:38\n",
            "\u001b[32m[08/06 14:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 140/400. 0.1835 s / img. ETA=0:01:33\n",
            "\u001b[32m[08/06 14:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 145/400. 0.1841 s / img. ETA=0:01:38\n",
            "\u001b[32m[08/06 14:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 149/400. 0.1848 s / img. ETA=0:01:42\n",
            "\u001b[32m[08/06 14:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 160/400. 0.1855 s / img. ETA=0:01:41\n",
            "\u001b[32m[08/06 14:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 179/400. 0.1853 s / img. ETA=0:01:34\n",
            "\u001b[32m[08/06 14:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 190/400. 0.1857 s / img. ETA=0:01:30\n",
            "\u001b[32m[08/06 14:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 203/400. 0.1865 s / img. ETA=0:01:24\n",
            "\u001b[32m[08/06 14:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 221/400. 0.1867 s / img. ETA=0:01:15\n",
            "\u001b[32m[08/06 14:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 235/400. 0.1869 s / img. ETA=0:01:09\n",
            "\u001b[32m[08/06 14:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 247/400. 0.1882 s / img. ETA=0:01:04\n",
            "\u001b[32m[08/06 14:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 262/400. 0.1884 s / img. ETA=0:00:58\n",
            "\u001b[32m[08/06 14:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 274/400. 0.1888 s / img. ETA=0:00:53\n",
            "\u001b[32m[08/06 14:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 291/400. 0.1886 s / img. ETA=0:00:45\n",
            "\u001b[32m[08/06 14:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 310/400. 0.1883 s / img. ETA=0:00:36\n",
            "\u001b[32m[08/06 14:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 334/400. 0.1877 s / img. ETA=0:00:25\n",
            "\u001b[32m[08/06 14:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 351/400. 0.1873 s / img. ETA=0:00:19\n",
            "\u001b[32m[08/06 14:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 357/400. 0.1875 s / img. ETA=0:00:17\n",
            "\u001b[32m[08/06 14:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 369/400. 0.1874 s / img. ETA=0:00:12\n",
            "\u001b[32m[08/06 14:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 387/400. 0.1874 s / img. ETA=0:00:05\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 400/400. 0.1872 s / img. ETA=0:00:00\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:36.851560 (0.397093 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:13 (0.187200 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 10_class/output/inference/10_class_val/coco_instances_results.json\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.15 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.232\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.654\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.686\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 15.867 | 23.212 | 19.337 |  nan  | 65.000 | 15.707 | 65.400 | 68.550 | 68.550  |  nan  | 65.000 | 68.582 |\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:49:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 10.038 | condiment  | 20.207 | bread       | 7.636  |\n",
            "| pasta           | 6.116  | milk       | 42.950 | egg         | 11.041 |\n",
            "| tinned tomatoes | 8.869  | butter     | 23.385 | baked beans | 14.551 |\n",
            "| soup            | 13.874 |            |        |             |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.21s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "COCOeval_opt.evaluate() finished in 0.31 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.233\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.216\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.850\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.763\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.799\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.799\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.799\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 19.442 | 23.279 | 21.595 |  nan  | 85.000 | 19.232 | 76.300 | 79.925 | 79.925  |  nan  | 85.000 | 79.923 |\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 11.998 | condiment  | 23.738 | bread       | 8.810  |\n",
            "| pasta           | 6.640  | milk       | 55.467 | egg         | 12.309 |\n",
            "| tinned tomatoes | 12.063 | butter     | 27.876 | baked beans | 18.834 |\n",
            "| soup            | 16.682 |            |        |             |        |\n",
            "\u001b[32m[08/06 14:49:13 detectron2]: \u001b[0mLog the eval results on Weights & Biases\n",
            "\u001b[32m[08/06 14:49:13 detectron2]: \u001b[0mEvaluation results for 10_class_val in csv format:\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.testing]: \u001b[0mcopypaste: 15.8667,23.2124,19.3372,nan,65.0000,15.7074,65.4000,68.5500,68.5500,nan,65.0000,68.5821\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:49:13 d2.evaluation.testing]: \u001b[0mcopypaste: 19.4417,23.2794,21.5948,nan,85.0000,19.2318,76.3000,79.9250,79.9250,nan,85.0000,79.9231\n",
            "\u001b[32m[08/06 14:49:13 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:49:13 d2.utils.events]: \u001b[0m eta: 1:22:29  iter: 1000  total_loss: 0.695  loss_cls: 0.285  loss_box_reg: 0.166  loss_mask: 0.161  loss_rpn_cls: 0.018  loss_rpn_loc: 0.038  lr: 0.002498  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:49:49 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:49:49 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 1020  total_loss: 0.538  loss_cls: 0.235  loss_box_reg: 0.132  loss_mask: 0.149  loss_rpn_cls: 0.012  loss_rpn_loc: 0.022  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:50:25 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:50:25 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 1040  total_loss: 0.624  loss_cls: 0.255  loss_box_reg: 0.130  loss_mask: 0.161  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:51:01 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:51:01 d2.utils.events]: \u001b[0m eta: 0:12:54  iter: 1060  total_loss: 0.473  loss_cls: 0.212  loss_box_reg: 0.098  loss_mask: 0.136  loss_rpn_cls: 0.012  loss_rpn_loc: 0.029  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:51:39 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:51:39 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 1080  total_loss: 0.438  loss_cls: 0.199  loss_box_reg: 0.085  loss_mask: 0.105  loss_rpn_cls: 0.010  loss_rpn_loc: 0.025  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:52:16 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:52:16 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 1100  total_loss: 0.534  loss_cls: 0.216  loss_box_reg: 0.098  loss_mask: 0.123  loss_rpn_cls: 0.010  loss_rpn_loc: 0.031  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:52:52 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:52:52 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 1120  total_loss: 0.485  loss_cls: 0.188  loss_box_reg: 0.091  loss_mask: 0.130  loss_rpn_cls: 0.008  loss_rpn_loc: 0.017  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:53:30 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:53:30 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 1140  total_loss: 0.549  loss_cls: 0.265  loss_box_reg: 0.114  loss_mask: 0.107  loss_rpn_cls: 0.008  loss_rpn_loc: 0.023  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:54:07 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:54:07 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 1160  total_loss: 0.558  loss_cls: 0.242  loss_box_reg: 0.118  loss_mask: 0.136  loss_rpn_cls: 0.012  loss_rpn_loc: 0.027  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:54:44 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:54:44 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 1180  total_loss: 0.481  loss_cls: 0.254  loss_box_reg: 0.106  loss_mask: 0.094  loss_rpn_cls: 0.007  loss_rpn_loc: 0.023  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:55:20 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:55:20 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 1200  total_loss: 0.366  loss_cls: 0.183  loss_box_reg: 0.078  loss_mask: 0.093  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:55:55 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:55:55 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 1220  total_loss: 0.480  loss_cls: 0.215  loss_box_reg: 0.099  loss_mask: 0.100  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 14:56:33 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:56:33 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 1240  total_loss: 0.511  loss_cls: 0.220  loss_box_reg: 0.116  loss_mask: 0.125  loss_rpn_cls: 0.008  loss_rpn_loc: 0.031  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 14:56:51 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 14:56:51 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 14:56:51 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 14:56:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[08/06 14:56:51 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/06 14:56:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 400 images\n",
            "\u001b[32m[08/06 14:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/400. 0.1805 s / img. ETA=0:01:29\n",
            "\u001b[32m[08/06 14:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 27/400. 0.1815 s / img. ETA=0:01:48\n",
            "\u001b[32m[08/06 14:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 48/400. 0.1822 s / img. ETA=0:01:33\n",
            "\u001b[32m[08/06 14:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 69/400. 0.1807 s / img. ETA=0:01:27\n",
            "\u001b[32m[08/06 14:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 81/400. 0.1823 s / img. ETA=0:01:32\n",
            "\u001b[32m[08/06 14:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 94/400. 0.1823 s / img. ETA=0:01:33\n",
            "\u001b[32m[08/06 14:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 103/400. 0.1825 s / img. ETA=0:01:39\n",
            "\u001b[32m[08/06 14:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 121/400. 0.1822 s / img. ETA=0:01:30\n",
            "\u001b[32m[08/06 14:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 141/400. 0.1812 s / img. ETA=0:01:24\n",
            "\u001b[32m[08/06 14:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 150/400. 0.1819 s / img. ETA=0:01:25\n",
            "\u001b[32m[08/06 14:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 163/400. 0.1824 s / img. ETA=0:01:22\n",
            "\u001b[32m[08/06 14:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 179/400. 0.1821 s / img. ETA=0:01:16\n",
            "\u001b[32m[08/06 14:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 193/400. 0.1826 s / img. ETA=0:01:12\n",
            "\u001b[32m[08/06 14:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 212/400. 0.1830 s / img. ETA=0:01:04\n",
            "\u001b[32m[08/06 14:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 224/400. 0.1837 s / img. ETA=0:01:01\n",
            "\u001b[32m[08/06 14:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 241/400. 0.1838 s / img. ETA=0:00:54\n",
            "\u001b[32m[08/06 14:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 254/400. 0.1845 s / img. ETA=0:00:51\n",
            "\u001b[32m[08/06 14:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 268/400. 0.1847 s / img. ETA=0:00:46\n",
            "\u001b[32m[08/06 14:58:32 d2.evaluation.evaluator]: \u001b[0mInference done 283/400. 0.1851 s / img. ETA=0:00:41\n",
            "\u001b[32m[08/06 14:58:37 d2.evaluation.evaluator]: \u001b[0mInference done 301/400. 0.1848 s / img. ETA=0:00:34\n",
            "\u001b[32m[08/06 14:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 324/400. 0.1843 s / img. ETA=0:00:25\n",
            "\u001b[32m[08/06 14:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 344/400. 0.1840 s / img. ETA=0:00:18\n",
            "\u001b[32m[08/06 14:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 357/400. 0.1840 s / img. ETA=0:00:14\n",
            "\u001b[32m[08/06 14:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 376/400. 0.1837 s / img. ETA=0:00:08\n",
            "\u001b[32m[08/06 14:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 389/400. 0.1839 s / img. ETA=0:00:03\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.960706 (0.339141 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.183744 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 10_class/output/inference/10_class_val/coco_instances_results.json\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.14 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.782\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.801\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.801\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.900\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 31.904 | 40.689 | 36.970 |  nan  | 90.000 | 31.724 | 78.200 | 80.100 | 80.100  |  nan  | 90.000 | 80.065 |\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:59:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 30.158 | condiment  | 25.376 | bread       | 22.677 |\n",
            "| pasta           | 23.756 | milk       | 56.853 | egg         | 34.075 |\n",
            "| tinned tomatoes | 24.625 | butter     | 41.765 | baked beans | 37.358 |\n",
            "| soup            | 22.396 |            |        |             |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "COCOeval_opt.evaluate() finished in 0.27 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.878\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.902\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.901\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |   APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |   ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:-------:|:------:|:------:|:------:|:-------:|:-----:|:-------:|:------:|\n",
            "| 36.405 | 40.673 | 37.972 |  nan  | 100.000 | 36.383 | 87.850 | 90.175 | 90.175  |  nan  | 100.000 | 90.141 |\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 33.072 | condiment  | 28.772 | bread       | 26.221 |\n",
            "| pasta           | 27.105 | milk       | 64.343 | egg         | 36.541 |\n",
            "| tinned tomatoes | 30.212 | butter     | 49.431 | baked beans | 42.098 |\n",
            "| soup            | 26.255 |            |        |             |        |\n",
            "\u001b[32m[08/06 14:59:09 detectron2]: \u001b[0mLog the eval results on Weights & Biases\n",
            "\u001b[32m[08/06 14:59:09 detectron2]: \u001b[0mEvaluation results for 10_class_val in csv format:\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: 31.9040,40.6891,36.9700,nan,90.0000,31.7237,78.2000,80.1000,80.1000,nan,90.0000,80.0647\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 14:59:09 d2.evaluation.testing]: \u001b[0mcopypaste: 36.4050,40.6730,37.9722,nan,100.0000,36.3832,87.8500,90.1750,90.1750,nan,100.0000,90.1410\n",
            "\u001b[32m[08/06 14:59:25 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 14:59:25 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 1260  total_loss: 0.525  loss_cls: 0.221  loss_box_reg: 0.109  loss_mask: 0.112  loss_rpn_cls: 0.009  loss_rpn_loc: 0.023  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:00:03 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:00:03 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 1280  total_loss: 0.520  loss_cls: 0.233  loss_box_reg: 0.109  loss_mask: 0.108  loss_rpn_cls: 0.009  loss_rpn_loc: 0.028  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:00:41 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:00:41 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1300  total_loss: 0.413  loss_cls: 0.215  loss_box_reg: 0.076  loss_mask: 0.088  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:01:18 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:01:18 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1320  total_loss: 0.385  loss_cls: 0.171  loss_box_reg: 0.077  loss_mask: 0.099  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:01:56 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:01:56 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 1340  total_loss: 0.346  loss_cls: 0.156  loss_box_reg: 0.071  loss_mask: 0.103  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:02:33 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:02:33 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 1360  total_loss: 0.346  loss_cls: 0.180  loss_box_reg: 0.068  loss_mask: 0.078  loss_rpn_cls: 0.005  loss_rpn_loc: 0.024  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:03:09 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:03:09 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 1380  total_loss: 0.339  loss_cls: 0.171  loss_box_reg: 0.073  loss_mask: 0.079  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:03:46 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:03:46 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 1400  total_loss: 0.330  loss_cls: 0.187  loss_box_reg: 0.068  loss_mask: 0.074  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:04:22 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:04:22 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 1420  total_loss: 0.395  loss_cls: 0.189  loss_box_reg: 0.087  loss_mask: 0.093  loss_rpn_cls: 0.005  loss_rpn_loc: 0.030  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:04:59 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:04:59 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 1440  total_loss: 0.512  loss_cls: 0.241  loss_box_reg: 0.109  loss_mask: 0.112  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  lr: 0.000500  max_mem: 11817M\n",
            "\u001b[32m[08/06 15:05:36 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:05:36 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 1460  total_loss: 0.425  loss_cls: 0.219  loss_box_reg: 0.090  loss_mask: 0.084  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  lr: 0.000500  max_mem: 11863M\n",
            "\u001b[32m[08/06 15:06:13 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:06:13 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 1480  total_loss: 0.310  loss_cls: 0.176  loss_box_reg: 0.070  loss_mask: 0.086  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  lr: 0.000500  max_mem: 11863M\n",
            "\u001b[32m[08/06 15:06:47 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to 10_class/output/model_final.pth\n",
            "\u001b[32m[08/06 15:07:02 detectron2]: \u001b[0mLogging iteration and loss to Weights & Biases\n",
            "\u001b[32m[08/06 15:07:02 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1500  total_loss: 0.355  loss_cls: 0.177  loss_box_reg: 0.082  loss_mask: 0.091  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  lr: 0.000500  max_mem: 11863M\n",
            "\u001b[32m[08/06 15:07:02 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to 10_class/output/model_final.pth\n",
            "\u001b[32m[08/06 15:07:05 detectron2]: \u001b[0mSaving model to Weights & Biases\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/06 15:07:17 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[08/06 15:07:17 d2.data.datasets.coco]: \u001b[0mLoaded 400 images in COCO format from 10_class/val/annotations.json\n",
            "\u001b[32m[08/06 15:07:17 d2.data.common]: \u001b[0mSerializing 400 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[08/06 15:07:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
            "\u001b[32m[08/06 15:07:17 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[08/06 15:07:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 400 images\n",
            "\u001b[32m[08/06 15:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/400. 0.1794 s / img. ETA=0:01:22\n",
            "\u001b[32m[08/06 15:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 27/400. 0.1822 s / img. ETA=0:01:47\n",
            "\u001b[32m[08/06 15:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 49/400. 0.1831 s / img. ETA=0:01:31\n",
            "\u001b[32m[08/06 15:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 69/400. 0.1817 s / img. ETA=0:01:25\n",
            "\u001b[32m[08/06 15:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 83/400. 0.1826 s / img. ETA=0:01:30\n",
            "\u001b[32m[08/06 15:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 97/400. 0.1826 s / img. ETA=0:01:29\n",
            "\u001b[32m[08/06 15:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 113/400. 0.1825 s / img. ETA=0:01:25\n",
            "\u001b[32m[08/06 15:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 135/400. 0.1810 s / img. ETA=0:01:17\n",
            "\u001b[32m[08/06 15:08:03 d2.evaluation.evaluator]: \u001b[0mInference done 148/400. 0.1810 s / img. ETA=0:01:16\n",
            "\u001b[32m[08/06 15:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 165/400. 0.1818 s / img. ETA=0:01:10\n",
            "\u001b[32m[08/06 15:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 184/400. 0.1813 s / img. ETA=0:01:04\n",
            "\u001b[32m[08/06 15:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 198/400. 0.1821 s / img. ETA=0:01:02\n",
            "\u001b[32m[08/06 15:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 221/400. 0.1825 s / img. ETA=0:00:54\n",
            "\u001b[32m[08/06 15:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 239/400. 0.1827 s / img. ETA=0:00:48\n",
            "\u001b[32m[08/06 15:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 252/400. 0.1833 s / img. ETA=0:00:45\n",
            "\u001b[32m[08/06 15:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 267/400. 0.1834 s / img. ETA=0:00:41\n",
            "\u001b[32m[08/06 15:08:47 d2.evaluation.evaluator]: \u001b[0mInference done 286/400. 0.1837 s / img. ETA=0:00:35\n",
            "\u001b[32m[08/06 15:08:52 d2.evaluation.evaluator]: \u001b[0mInference done 306/400. 0.1833 s / img. ETA=0:00:28\n",
            "\u001b[32m[08/06 15:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 332/400. 0.1830 s / img. ETA=0:00:20\n",
            "\u001b[32m[08/06 15:09:02 d2.evaluation.evaluator]: \u001b[0mInference done 351/400. 0.1827 s / img. ETA=0:00:14\n",
            "\u001b[32m[08/06 15:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 368/400. 0.1825 s / img. ETA=0:00:09\n",
            "\u001b[32m[08/06 15:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 387/400. 0.1826 s / img. ETA=0:00:03\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 400/400. 0.1824 s / img. ETA=0:00:00\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:58.313834 (0.299529 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:12 (0.182390 s / img per device, on 1 devices)\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to 10_class/output/inference/10_class_val/coco_instances_results.json\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 0.12 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.456\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.829\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.842\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.842\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.841\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |   APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |   ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:-------:|:------:|:------:|:------:|:-------:|:-----:|:-------:|:------:|\n",
            "| 40.562 | 48.469 | 45.641 |  nan  | 100.000 | 40.432 | 82.850 | 84.200 | 84.200  |  nan  | 100.000 | 84.135 |\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 15:09:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 42.833 | condiment  | 34.720 | bread       | 27.723 |\n",
            "| pasta           | 30.010 | milk       | 72.771 | egg         | 41.910 |\n",
            "| tinned tomatoes | 27.598 | butter     | 59.743 | baked beans | 45.278 |\n",
            "| soup            | 23.038 |            |        |             |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.12s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "COCOeval_opt.evaluate() finished in 0.26 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.896\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.912\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.912\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.950\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |  AR1   |  AR10  |  AR100  |  ARs  |  ARm   |  ARl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|:------:|:------:|:-------:|:-----:|:------:|:------:|\n",
            "| 44.228 | 48.470 | 46.065 |  nan  | 95.000 | 44.200 | 89.600 | 91.175 | 91.175  |  nan  | 95.000 | 91.171 |\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category        | AP     | category   | AP     | category    | AP     |\n",
            "|:----------------|:-------|:-----------|:-------|:------------|:-------|\n",
            "| cereal          | 45.820 | condiment  | 37.446 | bread       | 29.714 |\n",
            "| pasta           | 32.465 | milk       | 80.920 | egg         | 44.029 |\n",
            "| tinned tomatoes | 31.097 | butter     | 65.977 | baked beans | 49.448 |\n",
            "| soup            | 25.364 |            |        |             |        |\n",
            "\u001b[32m[08/06 15:09:19 detectron2]: \u001b[0mLog the eval results on Weights & Biases\n",
            "\u001b[32m[08/06 15:09:19 detectron2]: \u001b[0mEvaluation results for 10_class_val in csv format:\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.testing]: \u001b[0mcopypaste: 40.5623,48.4685,45.6414,nan,100.0000,40.4317,82.8500,84.2000,84.2000,nan,100.0000,84.1346\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl,AR1,AR10,AR100,ARs,ARm,ARl\n",
            "\u001b[32m[08/06 15:09:19 d2.evaluation.testing]: \u001b[0mcopypaste: 44.2280,48.4698,46.0645,nan,95.0000,44.2003,89.6000,91.1750,91.1750,nan,95.0000,91.1712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('bbox',\n",
              "              {'AP': 40.562345890421106,\n",
              "               'AP-baked beans': 45.27802198292877,\n",
              "               'AP-bread': 27.72289493999785,\n",
              "               'AP-butter': 59.743133959966435,\n",
              "               'AP-cereal': 42.83319561569085,\n",
              "               'AP-condiment': 34.71981120441652,\n",
              "               'AP-egg': 41.90978619898214,\n",
              "               'AP-milk': 72.77079348353067,\n",
              "               'AP-pasta': 30.009991399223594,\n",
              "               'AP-soup': 23.0375286832774,\n",
              "               'AP-tinned tomatoes': 27.598301436196778,\n",
              "               'AP50': 48.46853951718007,\n",
              "               'AP75': 45.64136341922232,\n",
              "               'APl': 40.431712149731325,\n",
              "               'APm': 100.0,\n",
              "               'APs': nan,\n",
              "               'AR1': 82.85000000000001,\n",
              "               'AR10': 84.20000000000002,\n",
              "               'AR100': 84.20000000000002,\n",
              "               'ARl': 84.1346153846154,\n",
              "               'ARm': 100.0,\n",
              "               'ARs': nan}),\n",
              "             ('segm',\n",
              "              {'AP': 44.227961998852074,\n",
              "               'AP-baked beans': 49.44761640288542,\n",
              "               'AP-bread': 29.71448991254833,\n",
              "               'AP-butter': 65.97707519714585,\n",
              "               'AP-cereal': 45.81974662815655,\n",
              "               'AP-condiment': 37.44552123848109,\n",
              "               'AP-egg': 44.02915838311417,\n",
              "               'AP-milk': 80.92041130475862,\n",
              "               'AP-pasta': 32.46486877518898,\n",
              "               'AP-soup': 25.364037981091897,\n",
              "               'AP-tinned tomatoes': 31.096694165149717,\n",
              "               'AP50': 48.46983728034107,\n",
              "               'AP75': 46.06453603234222,\n",
              "               'APl': 44.20031172565732,\n",
              "               'APm': 95.0,\n",
              "               'APs': nan,\n",
              "               'AR1': 89.60000000000001,\n",
              "               'AR10': 91.175,\n",
              "               'AR100': 91.175,\n",
              "               'ARl': 91.17115384615384,\n",
              "               'ARm': 95.0,\n",
              "               'ARs': nan})])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teremBzUozI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if TRAINING_CURVES:\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir output"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}