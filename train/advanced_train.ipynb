{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "advanced_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cCJlZut1Qx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code is based from the examples given in the detectron2 documentation.\n",
        "#\n",
        "# Authors:  Yuxin Wu, Alexander Kirillov, Francisco Massa,\n",
        "#           Wan-Yen Lo and Ross Girshick\n",
        "# Company:  Facebook AI Research\n",
        "# Year:     2019\n",
        "# Title:    plain_train.py\n",
        "# Type:     Source Code\n",
        "# URL:      https://github.com/facebookresearch/detectron2/blob/master/tools/plain_train_net.py\n",
        "#\n",
        "#\n",
        "# Authors:  Yuxin Wu, Alexander Kirillov, Francisco Massa,\n",
        "#           Wan-Yen Lo and Ross Girshick\n",
        "# Company:  Facebook AI Research\n",
        "# Year:     2019\n",
        "# Title:    Detectron2 Tutorial.ipynb\n",
        "# Type:     Source Code\n",
        "# URL:      https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh-JtnhqL1f_",
        "colab_type": "text"
      },
      "source": [
        "Show information about the assigned GPU resource:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoiJY38YZ0dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3I9ckI0L4J_",
        "colab_type": "text"
      },
      "source": [
        "Setup and instal dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DssQ2JMqbZiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpK6eu1ZL35y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "import torch, torchvision\n",
        "\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG2lDLZra2Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOyMPBJrsqwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5rTgBClrnje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyQvhnIa7Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import detectron2\n",
        "\n",
        "# Import common libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Import detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer  # Look into moving to a custom training loop to add weights & biases\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data import DatasetCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.config import get_cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9YRLhRkLAMA",
        "colab_type": "text"
      },
      "source": [
        "Connect to Google Drive (dataset stored on G drive due to size):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02yNu2Fahkto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My\\ Drive/Project/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-z9Jr93Nb9Z",
        "colab_type": "text"
      },
      "source": [
        "Define program setup and training parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOVifnng2-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['WANDB_API_KEY'] = 'your_weights_and_biases_API_key'\n",
        "\n",
        "# TOGGLE PROGRAM FUNCTIONALITY\n",
        "TEST_INPUT = False  # Toggles image read test\n",
        "TRAINING_CURVES = False  # Toggles Tensorboard training curves\n",
        "\n",
        "\n",
        "# PROGRAM CONSTANTS\n",
        "ROOT_DIR = \"10_class\"\n",
        "WANDB_PROJ = 'multi-class'\n",
        "model_name = \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
        "\n",
        "# TRAINING PARAMETERS\n",
        "num_classes = 10\n",
        "workers = 2\n",
        "ims_per_batch = 4\n",
        "seed = 27\n",
        "\n",
        "lr = 0.0025\n",
        "warmup_iters = 500\n",
        "max_iter = 25000\n",
        "step_low = 15000\n",
        "step_high = 25000\n",
        "gamma = 0.2\n",
        "momentum = 0.90\n",
        "eval_period = 2500\n",
        "\n",
        "# FILE PATHS\n",
        "TRAIN_DATASET_NAME = ROOT_DIR + \"_train\"\n",
        "TRAIN_ANNOTATIONS = ROOT_DIR + \"/train/annotations.json\"\n",
        "TRAIN_DIR = ROOT_DIR + \"/train\"\n",
        "\n",
        "TEST_DATASET_NAME = ROOT_DIR + \"_val\"\n",
        "TEST_ANNOTATIONS = ROOT_DIR + \"/val/annotations.json\"\n",
        "TEST_DIR = ROOT_DIR + \"/val\"\n",
        "\n",
        "output = ROOT_DIR + '/output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG1ZGsTCNiFB",
        "colab_type": "text"
      },
      "source": [
        "Register the dataset and add it the dataset catalog:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrmeoAawbTbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  register_coco_instances(TRAIN_DATASET_NAME, {}, TRAIN_ANNOTATIONS, TRAIN_DIR)\n",
        "  register_coco_instances(TEST_DATASET_NAME, {}, TEST_ANNOTATIONS, TEST_DIR)\n",
        "except (AssertionError):\n",
        "  print('Dataset has aready been registered!')\n",
        "\n",
        "train_metadata = MetadataCatalog.get(TRAIN_DATASET_NAME)\n",
        "dataset_dicts = DatasetCatalog.get(TRAIN_DATASET_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9mmDYadNwty",
        "colab_type": "text"
      },
      "source": [
        "Get a dictionary containing the number of object instances per class\n",
        "in the dataset. This will be logged to Weights and Biases later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPnSviwODxru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_bins = np.arange(num_classes + 1)\n",
        "histogram = np.zeros((num_classes,), dtype=np.int)\n",
        "for entry in dataset_dicts:\n",
        "  annos = entry[\"annotations\"]\n",
        "  classes = [x[\"category_id\"] for x in annos if not x.get(\"iscrowd\", 0)]\n",
        "  histogram += np.histogram(classes, bins=hist_bins)[0]\n",
        "\n",
        "class_instances = {('class_instances.' + train_metadata.thing_classes[i]): int(count) for i, count in enumerate(histogram)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9cPHhXsORjr",
        "colab_type": "text"
      },
      "source": [
        "Show a sample of image inputs for debug purposes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26pSZM1Af1EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if TEST_INPUT:\n",
        "  for d in random.sample(dataset_dicts, 3):\n",
        "      img = cv2.imread(d[\"file_name\"])\n",
        "      visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "      out = visualizer.draw_dataset_dict(d)\n",
        "      cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akQF-sL_OZUW",
        "colab_type": "text"
      },
      "source": [
        "Detectron2 training & test functions: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABvMGt82q_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import os\n",
        "from shutil import copyfile\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import (\n",
        "    MetadataCatalog,\n",
        "    build_detection_test_loader,\n",
        "    build_detection_train_loader,\n",
        ")\n",
        "from detectron2.engine import default_argument_parser, default_setup, launch\n",
        "from detectron2.evaluation import (\n",
        "    COCOEvaluator,\n",
        "    COCOPanopticEvaluator,\n",
        "    DatasetEvaluators,\n",
        "    SemSegEvaluator,\n",
        "    inference_on_dataset,\n",
        "    print_csv_format,\n",
        ")\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
        "from detectron2.utils.events import (\n",
        "    CommonMetricPrinter,\n",
        "    EventStorage,\n",
        "    JSONWriter,\n",
        "    TensorboardXWriter,\n",
        ")\n",
        "\n",
        "# Setup logger\n",
        "logger = logging.getLogger(\"detectron2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3cBPAMR25GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_evaluator(cfg, dataset_name, output_folder=None):\n",
        "    \"\"\"\n",
        "    Create evaluator(s) for a given dataset.\n",
        "    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
        "    For your own dataset, you can simply create an evaluator manually in your\n",
        "    script and do not have to worry about the hacky if-else logic here.\n",
        "\n",
        "    # TODO: Edit docstring\n",
        "\n",
        "    \"\"\"\n",
        "    if output_folder is None:\n",
        "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "    evaluator_list = []\n",
        "\n",
        "    evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n",
        "    if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(\n",
        "            SemSegEvaluator(\n",
        "                dataset_name,\n",
        "                distributed=True,\n",
        "                num_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES,\n",
        "                ignore_label=cfg.MODEL.SEM_SEG_HEAD.IGNORE_VALUE,\n",
        "                output_dir=output_folder,\n",
        "            )\n",
        "        )\n",
        "    if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n",
        "        evaluator_list.append(COCOEvaluator(dataset_name, cfg, True, output_folder))\n",
        "    if evaluator_type == \"coco_panoptic_seg\":\n",
        "        evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n",
        "\n",
        "    if len(evaluator_list) == 0:\n",
        "        raise NotImplementedError(\n",
        "            \"no Evaluator for the dataset {} with the type {}\".format(dataset_name, evaluator_type)\n",
        "        )\n",
        "    if len(evaluator_list) == 1:\n",
        "        return evaluator_list[0]\n",
        "    return DatasetEvaluators(evaluator_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj74pNfF26zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_test(cfg, model):\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Write docstring\n",
        "    \"\"\"\n",
        "    # Initialise results dictionary\n",
        "    results = OrderedDict()\n",
        "\n",
        "    # Loop through the datasets in the config file\n",
        "    for dataset_name in cfg.DATASETS.TEST:\n",
        "        data_loader = build_detection_test_loader(cfg, dataset_name)\n",
        "\n",
        "        # Generate the evaluator\n",
        "        evaluator = get_evaluator(\n",
        "            cfg,\n",
        "            dataset_name,\n",
        "            os.path.join(cfg.OUTPUT_DIR, \"inference\", dataset_name)\n",
        "        )\n",
        "\n",
        "        # Run inference and add to results dictionary\n",
        "        results_i = inference_on_dataset(model, data_loader, evaluator)\n",
        "        results[dataset_name] = results_i\n",
        "\n",
        "        # Log the result set to weights and biases\n",
        "        result_log = {}\n",
        "        result_dict = results_i\n",
        "        for iou_type in result_dict:\n",
        "          for metric, result in result_dict[iou_type].items():\n",
        "            metric_log = f\"{iou_type}_{metric}\"\n",
        "            result_log[metric_log] = result\n",
        "\n",
        "        logger.debug('Log the eval results on Weights & Biases')\n",
        "        wandb.log(result_log)\n",
        "\n",
        "        # Print to terminal\n",
        "        if comm.is_main_process():\n",
        "            logger.info(\"Evaluation results for {} in csv format:\".format(dataset_name))\n",
        "            print_csv_format(results_i)\n",
        "    if len(results) == 1:\n",
        "        results = list(results.values())[0]\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzsH_C5D2-Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_train(cfg, model, resume=False):\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Write docstring\n",
        "    \"\"\"\n",
        "    # Set the model to train\n",
        "    model.train()\n",
        "\n",
        "    # Create torch optimiser & schedulars\n",
        "    optimizer = build_optimizer(cfg, model)\n",
        "    scheduler = build_lr_scheduler(cfg, optimizer)\n",
        "\n",
        "    # Create a torch checkpointer\n",
        "    checkpointer = DetectionCheckpointer(\n",
        "        model, cfg.OUTPUT_DIR, optimizer=optimizer, scheduler=scheduler\n",
        "    )\n",
        "\n",
        "    # Create starting checkpoint i.e. pre-trained model using weights from config\n",
        "    start_iter = (\n",
        "        checkpointer.resume_or_load(cfg.MODEL.WEIGHTS, resume=resume).get(\"iteration\", -1) + 1\n",
        "    )\n",
        "\n",
        "    # Define the number of iterations\n",
        "    max_iter = cfg.SOLVER.MAX_ITER\n",
        "\n",
        "    # Create a periodic checkpointer at the configured period\n",
        "    periodic_checkpointer = PeriodicCheckpointer(\n",
        "        checkpointer, cfg.SOLVER.CHECKPOINT_PERIOD, max_iter=max_iter\n",
        "    )\n",
        "\n",
        "    # Export checkpoint data to terminal, JSON & tensorboard files\n",
        "    writers = (\n",
        "        [\n",
        "            CommonMetricPrinter(max_iter),\n",
        "            JSONWriter(os.path.join(cfg.OUTPUT_DIR, \"metrics.json\")),\n",
        "            TensorboardXWriter(cfg.OUTPUT_DIR),\n",
        "        ]\n",
        "        if comm.is_main_process()\n",
        "        else []\n",
        "    )\n",
        "\n",
        "    # Create a data loader to supply the model with training data\n",
        "    data_loader = build_detection_train_loader(cfg)\n",
        "\n",
        "    logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
        "    with EventStorage(start_iter) as storage:\n",
        "        for data, iteration in zip(data_loader, range(start_iter, max_iter)):\n",
        "            iteration = iteration + 1\n",
        "            storage.step()\n",
        "\n",
        "            loss_dict = model(data)\n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                storage.put_scalars(total_loss=losses_reduced, **loss_dict_reduced)\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            storage.put_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], smoothing_hint=False)\n",
        "            scheduler.step()\n",
        "\n",
        "            # If eval period has been set, run test at defined interval\n",
        "            if (\n",
        "                cfg.TEST.EVAL_PERIOD > 0\n",
        "                and iteration % cfg.TEST.EVAL_PERIOD == 0\n",
        "                and iteration != max_iter\n",
        "            ):\n",
        "                do_test(cfg, model)\n",
        "                comm.synchronize()\n",
        "\n",
        "            if iteration - start_iter > 5 and (iteration % 20 == 0 or iteration == max_iter):\n",
        "                logger.debug('Logging iteration and loss to Weights & Biases')\n",
        "                wandb.log({\"iteration\": iteration})\n",
        "                wandb.log({\"total_loss\": losses_reduced})\n",
        "                wandb.log(loss_dict_reduced)\n",
        "\n",
        "                for writer in writers:\n",
        "                    writer.write()\n",
        "            periodic_checkpointer.step(iteration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTnsfBqp3Ckj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup(args, model_name):\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(args.config_file)\n",
        "    cfg.merge_from_list(args.opts)\n",
        "\n",
        "    cfg.freeze()\n",
        "\n",
        "    # Log the configuration file to OUTPUT_DIR\n",
        "    default_setup(\n",
        "        cfg, args\n",
        "    )\n",
        "\n",
        "    # Set up the weights and biases project\n",
        "    logger.debug('Initialising Weights & Biases project')\n",
        "    wandb.init(project=WANDB_PROJ, sync_tensorboard=False)\n",
        "\n",
        "    # Load the yaml file and export it to wandb\n",
        "    cfg_export = cfg.load_yaml_with_base(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"))\n",
        "    logger.debug(\"Saving cfg file to Weights & Biases\")\n",
        "    wandb.config.update(cfg_export)\n",
        "\n",
        "    # Log train and val set sizes\n",
        "    wandb.config.update({\"CONFIG_FILE\": model_name})\n",
        "    wandb.config.update({\"train_imgs\": len(dataset_dicts)})\n",
        "    wandb.config.update({\"test_imgs\": len(DatasetCatalog.get(TEST_DATASET_NAME))})\n",
        "    wandb.config.update(class_instances)\n",
        "\n",
        "    return cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK8qyY0Z3Vws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(args, model_name):\n",
        "    # Initialise the configuration datastructure\n",
        "    cfg = setup(args, model_name)\n",
        "\n",
        "    # Build a model from the configuration file\n",
        "    model = build_model(cfg)\n",
        "\n",
        "    logger.info(\"Model:\\n{}\".format(model))\n",
        "\n",
        "    # If the 'eval_only' argument is present, load the last checkpoint\n",
        "    # and return the results of the test function\n",
        "    if args.eval_only:\n",
        "        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
        "            cfg.MODEL.WEIGHTS, resume=args.resume\n",
        "        )\n",
        "        return do_test(cfg, model)\n",
        "\n",
        "    # Run the training loop\n",
        "    do_train(cfg, model, resume=args.resume)\n",
        "\n",
        "    # Save model to weights and biases\n",
        "    logger.debug('Saving model to Weights & Biases')\n",
        "    copyfile(ROOT_DIR + '/output/model_final.pth', wandb.run.dir + '/model_final.pth')\n",
        "\n",
        "    # Return the results of the model test function\n",
        "    return do_test(cfg, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buFXyrw-FiZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up an argument string to pass into the main function\n",
        "\n",
        "config = model_zoo.get_config_file(model_name)\n",
        "weights = model_zoo.get_checkpoint_url(model_name)\n",
        "\n",
        "arg_string = f\"--config-file {config} \\\n",
        "              MODEL.WEIGHTS {weights} \\\n",
        "              OUTPUT_DIR {output} \\\n",
        "              DATASETS.TRAIN ('{TRAIN_DATASET_NAME}',) \\\n",
        "              DATASETS.TEST ('{TEST_DATASET_NAME}',) \\\n",
        "              DATALOADER.NUM_WORKERS {workers} \\\n",
        "              SOLVER.IMS_PER_BATCH {ims_per_batch} \\\n",
        "              SOLVER.BASE_LR {lr} \\\n",
        "              SOLVER.WARMUP_ITERS {warmup_iters} \\\n",
        "              SOLVER.MAX_ITER {max_iter} \\\n",
        "              SOLVER.STEPS ({step_low},{step_high}) \\\n",
        "              SOLVER.GAMMA {gamma} \\\n",
        "              SOLVER.MOMENTUM {momentum} \\\n",
        "              SEED {seed} \\\n",
        "              MODEL.ROI_HEADS.NUM_CLASSES {num_classes} \\\n",
        "              MODEL.RETINANET.NUM_CLASSES {num_classes} \\\n",
        "              TEST.EVAL_PERIOD {eval_period}\".split()\n",
        "\n",
        "parser = default_argument_parser()\n",
        "args = parser.parse_args(arg_string)\n",
        "\n",
        "main(args, model_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}